{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nfrom collections import defaultdict\nimport cv2\n\n# import SimpleITK as sitk\nimport collections\n\nfrom pathlib import Path\nimport numpy as np\nimport gc\n\nimport pandas as pd\nimport polars as pl\nimport pydicom\nimport ipywidgets as widgets\nimport glob\nfrom scipy.ndimage import zoom\nfrom scipy import ndimage\n\nimport csv\nimport copy\n\nfrom functools import lru_cache\n\nimport torch\nimport torch.cuda\nfrom torch.utils.data import Dataset\n\nimport kaggle_evaluation.rsna_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T06:42:25.578073Z","iopub.execute_input":"2025-10-14T06:42:25.578381Z","iopub.status.idle":"2025-10-14T06:42:30.991504Z","shell.execute_reply.started":"2025-10-14T06:42:25.578358Z","shell.execute_reply":"2025-10-14T06:42:30.990456Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/4223391456.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsna_inference_server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_evaluation'"],"ename":"ModuleNotFoundError","evalue":"No module named 'kaggle_evaluation'","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in `rsna_gateway` will run in a different container with direct access to the hidden test set and hand off the data series by series.\n\nYour code will always have access to the published copies of the files.","metadata":{}},{"cell_type":"code","source":"ID_COL = 'SeriesInstanceUID'\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\n# All tags (other than PixelData and SeriesInstanceUID) that may be in a test set dcm file\nDICOM_TAG_ALLOWLIST = [\n    'BitsAllocated',\n    'BitsStored',\n    'Columns',\n    'FrameOfReferenceUID',\n    'HighBit',\n    'ImageOrientationPatient',\n    'ImagePositionPatient',\n    'InstanceNumber',\n    'Modality',\n    'PatientID',\n    'PhotometricInterpretation',\n    'PixelRepresentation',\n    'PixelSpacing',\n    'PlanarConfiguration',\n    'RescaleIntercept',\n    'RescaleSlope',\n    'RescaleType',\n    'Rows',\n    'SOPClassUID',\n    'SOPInstanceUID',\n    'SamplesPerPixel',\n    'SliceThickness',\n    'SpacingBetweenSlices',\n    'StudyInstanceUID',\n    'TransferSyntaxUID',\n]\n\n# Replace this function with your inference code.\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each prediction (except the very first) must be returned within 30 minutes of the series being provided.\ndef predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # --------- Replace this section with your own prediction code ---------\n    series_id = os.path.basename(series_path)\n    \n    all_filepaths = []\n    for root, _, files in os.walk(series_path):\n        for file in files:\n            if file.endswith('.dcm'):\n                all_filepaths.append(os.path.join(root, file))\n    all_filepaths.sort()\n    \n    # Collect tags from the dicoms\n    tags = defaultdict(list)\n    tags['SeriesInstanceUID'] = series_id\n    global dcms\n    for filepath in all_filepaths:\n        ds = pydicom.dcmread(filepath, force=True)\n        tags['filepath'].append(filepath)\n        for tag in DICOM_TAG_ALLOWLIST:\n            tags[tag].append(getattr(ds, tag, None))\n        # The image is in ds.PixelData\n\n    # ... do some machine learning magic ...\n    predictions = pl.DataFrame(\n        data=[[series_id] + [0.5] * len(LABEL_COLS)],\n        schema=[ID_COL, *LABEL_COLS],\n        orient='row',\n    )\n    # ----------------------------------------------------------------------\n\n    if isinstance(predictions, pl.DataFrame):\n        assert predictions.columns == [ID_COL, *LABEL_COLS]\n    elif isinstance(predictions, pd.DataFrame):\n        assert (predictions.columns == [ID_COL, *LABEL_COLS]).all()\n    else:\n        raise TypeError('The predict function must return a DataFrame')\n\n    # ----------------------------- IMPORTANT ------------------------------\n    # You MUST have the following code in your `predict` function\n    # to prevent \"out of disk space\" errors. This is a temporary workaround\n    # as we implement improvements to our evaluation system.\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    # ----------------------------------------------------------------------\n    \n    return predictions.drop(ID_COL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:37:24.078063Z","iopub.execute_input":"2025-10-13T16:37:24.078505Z","iopub.status.idle":"2025-10-13T16:37:24.088057Z","shell.execute_reply.started":"2025-10-13T16:37:24.078483Z","shell.execute_reply":"2025-10-13T16:37:24.087398Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"When your notebook is run on the hidden test set, `inference_server.serve` must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first `predict` call.","metadata":{}},{"cell_type":"code","source":"inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway()\n    display(pl.read_parquet('/kaggle/working/submission.parquet'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:37:31.430430Z","iopub.execute_input":"2025-10-13T16:37:31.431184Z","iopub.status.idle":"2025-10-13T16:37:45.558665Z","shell.execute_reply.started":"2025-10-13T16:37:31.431154Z","shell.execute_reply":"2025-10-13T16:37:45.557915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"shape: (3, 15)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ SeriesIns ┆ Left Infr ┆ Right Inf ┆ Left Supr ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm │\n│ tanceUID  ┆ aclinoid  ┆ raclinoid ┆ aclinoid  ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present  │\n│ ---       ┆ Internal  ┆ Internal  ┆ Internal  ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---      │\n│ str       ┆ Car…      ┆ Ca…       ┆ Car…      ┆   ┆ ting …    ┆ f64       ┆ on        ┆ f64      │\n│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆           ┆ ---       ┆          │\n│           ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ 1.2.826.0 ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ … ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ 0.5      │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 005…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 1.2.826.0 ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ … ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ 0.5      │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 002…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 1.2.826.0 ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ … ┆ 0.5       ┆ 0.5       ┆ 0.5       ┆ 0.5      │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 007…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.1005…</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1002…</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1007…</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td><td>0.5</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# 데이터 경로 정리","metadata":{}},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection'\nSERIES_PATH = os.path.join(DATA_PATH,'series')\nSEG_PATH = os.path.join(DATA_PATH,'segmentations')\ntrain_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ntrain_localizers_df = pd.read_csv(os.path.join(DATA_PATH, 'train_localizers.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:38:06.622178Z","iopub.execute_input":"2025-10-13T16:38:06.622856Z","iopub.status.idle":"2025-10-13T16:38:06.655350Z","shell.execute_reply.started":"2025-10-13T16:38:06.622834Z","shell.execute_reply":"2025-10-13T16:38:06.654792Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 검증용 데이터 분리 \nfrom sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(train_df, test_size = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:38:08.079161Z","iopub.execute_input":"2025-10-13T16:38:08.079446Z","iopub.status.idle":"2025-10-13T16:38:08.090702Z","shell.execute_reply.started":"2025-10-13T16:38:08.079424Z","shell.execute_reply":"2025-10-13T16:38:08.090087Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:38:11.422796Z","iopub.execute_input":"2025-10-13T16:38:11.423072Z","iopub.status.idle":"2025-10-13T16:38:11.445958Z","shell.execute_reply.started":"2025-10-13T16:38:11.423055Z","shell.execute_reply":"2025-10-13T16:38:11.445401Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 3478 entries, 2804 to 2853\nData columns (total 18 columns):\n #   Column                                      Non-Null Count  Dtype \n---  ------                                      --------------  ----- \n 0   SeriesInstanceUID                           3478 non-null   object\n 1   PatientAge                                  3478 non-null   int64 \n 2   PatientSex                                  3478 non-null   object\n 3   Modality                                    3478 non-null   object\n 4   Left Infraclinoid Internal Carotid Artery   3478 non-null   int64 \n 5   Right Infraclinoid Internal Carotid Artery  3478 non-null   int64 \n 6   Left Supraclinoid Internal Carotid Artery   3478 non-null   int64 \n 7   Right Supraclinoid Internal Carotid Artery  3478 non-null   int64 \n 8   Left Middle Cerebral Artery                 3478 non-null   int64 \n 9   Right Middle Cerebral Artery                3478 non-null   int64 \n 10  Anterior Communicating Artery               3478 non-null   int64 \n 11  Left Anterior Cerebral Artery               3478 non-null   int64 \n 12  Right Anterior Cerebral Artery              3478 non-null   int64 \n 13  Left Posterior Communicating Artery         3478 non-null   int64 \n 14  Right Posterior Communicating Artery        3478 non-null   int64 \n 15  Basilar Tip                                 3478 non-null   int64 \n 16  Other Posterior Circulation                 3478 non-null   int64 \n 17  Aneurysm Present                            3478 non-null   int64 \ndtypes: int64(15), object(3)\nmemory usage: 516.3+ KB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# train 데이터 그래프\n- 연령 : 50 ~ 70대 다수\n- 동맥류 없는 경우가 훨씬 많음\n","metadata":{}},{"cell_type":"code","source":"train_df.hist(figsize=(20,20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:04.443578Z","iopub.execute_input":"2025-10-11T13:58:04.444886Z","iopub.status.idle":"2025-10-11T13:58:08.880453Z","shell.execute_reply.started":"2025-10-11T13:58:04.444802Z","shell.execute_reply":"2025-10-11T13:58:08.879214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:08.882621Z","iopub.execute_input":"2025-10-11T13:58:08.883088Z","iopub.status.idle":"2025-10-11T13:58:08.904366Z","shell.execute_reply.started":"2025-10-11T13:58:08.882984Z","shell.execute_reply":"2025-10-11T13:58:08.903010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_localizers_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:08.905574Z","iopub.execute_input":"2025-10-11T13:58:08.905874Z","iopub.status.idle":"2025-10-11T13:58:08.947329Z","shell.execute_reply.started":"2025-10-11T13:58:08.905850Z","shell.execute_reply":"2025-10-11T13:58:08.946049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_localizers_df.head()\n# 여기서 왜 coordinates가 x와 y정보만 있을까? ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:08.948401Z","iopub.execute_input":"2025-10-11T13:58:08.948742Z","iopub.status.idle":"2025-10-11T13:58:08.973329Z","shell.execute_reply.started":"2025-10-11T13:58:08.948690Z","shell.execute_reply":"2025-10-11T13:58:08.972330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. DICOM series 불러오기 및 3D volumn 만들기 \n\n## 이 과정의 의미와 필요성\n\n**DICOM 시리즈 불러오기 및 3D 볼륨 만들기**는 의료 영상(특히 CT, MRI 등)에서 여러 장의 2D 슬라이스 이미지를 순서대로 불러와서, 이를 하나의 3차원(3D) 데이터로 합치는 과정이야. \n\n### 왜 필요한가?\n- **의료 영상 데이터는 대부분 2D 슬라이스(얇게 자른 단면 이미지)로 저장**돼 있어. 한 환자의 CT 검사 결과는 수십~수백 장의 DICOM 파일(각각 한 슬라이스)로 제공됨.[1][6]\n- 이 슬라이스들을 올바른 순서로 쌓으면, **3D 볼륨(입체 영상)**을 만들 수 있어. 이렇게 하면 실제 인체 구조를 입체적으로 분석하거나, 3D로 시각화, 딥러닝 모델 입력 등 다양한 분석이 가능해.[2][3][4]\n- 예를 들어, 뇌 동맥류 위치를 3D로 파악하거나, 3D 마스크와 비교할 때 꼭 필요해.\n\n## 과정 요약\n1. **폴더에서 모든 DICOM 파일(슬라이스) 불러오기**\n2. **슬라이스 순서대로 정렬** (보통 파일명 또는 DICOM 메타데이터의 위치 정보 활용)\n3. **각 슬라이스의 픽셀 데이터를 3D 배열로 쌓기**\n\n***\n\n## 코드 예시와 설명\n\n```python\nimport os\nimport pydicom\nimport numpy as np\n\n# 1. 시리즈 폴더 경로 지정 (실제 SeriesInstanceUID로 변경)\nseries_dir = 'series/1.2.826.0.1.3680043.12345'\n\n# 2. 폴더 내 모든 DICOM 파일 경로 리스트업\nfiles = [os.path.join(series_dir, f) for f in os.listdir(series_dir) if f.endswith('.dcm')]\n\n# 3. DICOM 파일을 모두 읽어서 리스트로 저장\nslices = [pydicom.dcmread(f) for f in files]\n\n# 4. (선택) 슬라이스를 위치 정보로 정렬 (SliceLocation, InstanceNumber 등)\nslices = sorted(slices, key=lambda s: float(s.InstanceNumber))\n\n# 5. 각 슬라이스의 픽셀 데이터를 3D 배열로 쌓기\nvolume = np.stack([s.pixel_array for s in slices])\nprint('3D 볼륨 shape:', volume.shape)  # (슬라이스 수, 높이, 너비)\n```\n\n### 코드 설명\n- **1~2단계:** 한 시리즈 폴더(한 번의 CT/MRI 촬영 결과)에서 모든 DICOM 파일을 찾음.\n- **3단계:** 각 파일을 pydicom으로 읽어서 DICOM 객체 리스트로 만듦.\n- **4단계:** 슬라이스가 올바른 순서(머리→발, 앞→뒤 등)로 쌓이도록 정렬. InstanceNumber, SliceLocation 등 메타데이터를 활용함.[6]\n- **5단계:** 각 슬라이스의 픽셀 데이터를 numpy 배열로 추출해서, (슬라이스 수, 높이, 너비) 형태의 3D 볼륨을 만듦.\n\n***\n\n## 요약\n- 이 과정은 **2D 슬라이스를 3D 입체 영상으로 재구성**하는 핵심 단계야.\n- 3D 볼륨이 있어야 실제 인체 구조 분석, 3D 시각화, 딥러닝 모델 입력 등 다양한 의료 영상 분석이 가능해진다.[3][4][1][2][6]","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\n\ndataset = pydicom.dcmread(path)\npixel_array = dataset.pixel_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:08.975857Z","iopub.execute_input":"2025-10-11T13:58:08.978468Z","iopub.status.idle":"2025-10-11T13:58:09.026863Z","shell.execute_reply.started":"2025-10-11T13:58:08.978436Z","shell.execute_reply":"2025-10-11T13:58:09.025449Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\n\nseries_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647'\n\n# 슬라이스 파일 정렬 및 읽기\nfiles = sorted([os.path.join(series_dir, f) for f in os.listdir(series_dir) if f.endswith('.dcm')])\nslices = [pydicom.dcmread(f) for f in files]\n\n# 3D 볼륨 생성\nvolume = np.stack([s.pixel_array for s in slices])\nprint('3D 볼륨 shape:', volume.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:09.028043Z","iopub.execute_input":"2025-10-11T13:58:09.028316Z","iopub.status.idle":"2025-10-11T13:58:13.645920Z","shell.execute_reply.started":"2025-10-11T13:58:09.028294Z","shell.execute_reply":"2025-10-11T13:58:13.644786Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 가운데 슬라이스 시각화\nmid = len(volume) // 2\nplt.imshow(volume[mid], cmap='gray')\nplt.title('Middle Slice')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:13.648882Z","iopub.execute_input":"2025-10-11T13:58:13.649320Z","iopub.status.idle":"2025-10-11T13:58:13.852667Z","shell.execute_reply.started":"2025-10-11T13:58:13.649290Z","shell.execute_reply":"2025-10-11T13:58:13.851619Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DICOM 파일 시리즈 읽기\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(series_dir)\nreader.SetFileNames(dicom_names)\n\n# DICOM 시리즈를 읽어 이미지로 변환\nimage = reader.Execute()\n\n# 이미지 정보 확인\nprint(f\"Image size: {image.GetSize()}\")   # 이미지의 크기\nprint(f\"Pixel spacing: {image.GetSpacing()}\")  # 픽셀 간격\n\n\n# numpy 배열로 변환\nimage_array = sitk.GetArrayFromImage(image)\nprint(image_array.shape)  # numpy 배열의 크기","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:13.853998Z","iopub.execute_input":"2025-10-11T13:58:13.854282Z","iopub.status.idle":"2025-10-11T13:58:23.867665Z","shell.execute_reply.started":"2025-10-11T13:58:13.854261Z","shell.execute_reply":"2025-10-11T13:58:23.866800Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(image_array[0], cmap='gray')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:23.868772Z","iopub.execute_input":"2025-10-11T13:58:23.869113Z","iopub.status.idle":"2025-10-11T13:58:24.058545Z","shell.execute_reply.started":"2025-10-11T13:58:23.869081Z","shell.execute_reply":"2025-10-11T13:58:24.057555Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\ndicom_image = sitk.ReadImage(path)\n\n# 1. 원점 가져오기\norigin = dicom_image.GetOrigin()\nprint(\"원점\", origin) \n# 원점 (-83.338355229404, -79.849251419771, 38.935824681372)\n\n# 2. 크기 가져오기\nsize = dicom_image.GetSize()\nprint(\"크기 : \", size) # 크기 :  (512, 512, 1)\n\n# 3. 깊이 가져오기\ndepth = dicom_image.GetDepth()\nprint('깊이:',depth) # 깊이: 1\n\n# 4. 특정 위치의 픽셀 값 가져오기\npixel_location = (0,0,0)\npixel_value = dicom_image.GetPixel(*pixel_location)\n\nprint('픽셀 값 (0,0,0):', pixel_value) # 픽셀 값 (0,0,0): 0\n\n# 5. 원점 설정하기 \nnew_origin = [0.0, 0.0, 0.0]\ndicom_image.SetOrigin(new_origin)\n\nprint('새 원점 설정 완료', new_origin)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.059919Z","iopub.execute_input":"2025-10-11T13:58:24.060297Z","iopub.status.idle":"2025-10-11T13:58:24.146434Z","shell.execute_reply.started":"2025-10-11T13:58:24.060256Z","shell.execute_reply":"2025-10-11T13:58:24.145231Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 동맥류 여부 변수, x,y, series_uid를 담을 튜플 정의 ","metadata":{}},{"cell_type":"code","source":"CandidateInfoTuple = collections.namedtuple('CandidateInfoTuple',\n                                            'is_aneurysm_present, series_uid, sop_uid, center_xyz')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.147807Z","iopub.execute_input":"2025-10-11T13:58:24.148075Z","iopub.status.idle":"2025-10-11T13:58:24.152988Z","shell.execute_reply.started":"2025-10-11T13:58:24.148054Z","shell.execute_reply":"2025-10-11T13:58:24.151429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## serise/ 내의 series_uid 폴더 별 dicom 이미지를 3D array로 변환","metadata":{}},{"cell_type":"code","source":"class DICOMPreprocessor:   \n\n    def __init__(self, target_shape = (16, 128, 128)):\n        self.target_depth , self.target_height, self.target_width = target_shape\n    \n    \"\"\"\n       Load DICOM series\n       \"\"\"\n    \n    @lru_cache(1) # @lru_cache(1) 수의 결과를 캐싱해준다. 호출 결과가 이미 캐싱되어있으면 함수를 호출하지않고 캐싱된 결과를 반환한다.\n    def load_dicom_series(self, series_path):\n        dicom_files = []\n\n        series_path = Path(series_path)\n        series_name = series_path.name \n        \n        # os.walk : 모든 하위 파일까지 다 탐색 가능 , (경로, 경로 내 디렉토리 리스트, 경로 내 파일 리스트)\n    \n        for root, _ , files in os.walk(series_path): \n            for file in files:\n                if file.endswith('.dcm'):\n                    dicom_files.append(os.path.join(root,file))\n        if not dicom_files:\n            raise ValueError(f\"no Dicom files found in {series_path}\")\n        print(f\"Found {len(dicom_files)} DICOM files in series {series_path}\")\n    \n        # Load DICOM datasets\n        datasets = []\n    \n        for filepath in dicom_files:\n            try:\n                ds = pydicom.dcmread(filepath)\n                datasets.append(ds)\n            except Exception as e:\n                print(f\"Failed to load {filepath}: {e}\")\n                continue\n        if not datasets : \n            raise ValueError(f\"No valid DICOM files in {series_path}\")\n        return datasets , series_name\n    \n    \n    \"\"\"\n    Extract position information for each slice \n    \"\"\"\n    def extract_slice_info(self, datasets):\n        slice_info = []\n        for i, ds in enumerate(datasets):\n            info = {\n                'dataset' : ds,\n                'index' : i,\n                'instance_number' : getattr(ds, 'InstanceNumber',i)\n            }\n    \n    # Get z-coordinate from ImagePositionPatient and ImageOrientationPatient\n            try:\n                ipp = np.array(getattr(ds, 'ImagePositionPatient',None))\n                iop = np.array(getattr(ds, 'ImageOrientationPatient', None))\n                n_vec = np.cross(iop[:3],iop[3:])\n                if iop is None:\n                    info['z_position'] = float(i)\n                else:\n                    info['z_position'] = -float((ipp*n_vec).sum())\n            except Exception as e:\n                info['z_position'] = float(i)\n                print(f\"failed to extract position info, {i}: {e}\")\n            slice_info.append(info)\n        return slice_info\n    \n    \"\"\"\n    Sort slices by z-coordinate\n    \"\"\"\n    def sort_slices_by_position(self, slice_info):\n        sorted_slices = sorted(slice_info, key = lambda x : x['z_position'])\n        return sorted_slices\n    \n    \n    '''\n    Get windowing parameters based on modality\n    - CT 이미지에 대해서만 윈도잉을 하는 이유 \n    windowing : CT 영상에서 나타나는 선형 밀도(HU)를 영상의 특정 범위(윈도우)로 제한해 명암대비를 조절하는 과정\n    전체 HU 범위를 영상으로 그대로 표현하면, 눈으롱 인지하기 어려울 정도의 넓은 명암 범위가 생성됨\n    특정 관심 조직을 부각하기 위해서는 윈도우 폭과 중심을 조절해 해당 조직의 HU 범위를 적절히 드러냄\n    \n    '''\n    def get_windowing_params(self, ds:pydicom.Dataset, img:np.ndarray=None) :\n        modality = getattr(ds,'Modality','CT') \n    \n        if modality == 'CT':\n            # For CT , apply CTA settings\n            # center : widnow level (윈도우 중심)\n            # 50인 경우 HU 50을 기준으로 대칭적인 구간 50 +- width/2를 윈도우 범위로 설정\n            # 폭이 넓으면 대비가 낮아지고, 폭이 조으면 대비가 높아진다. \n            # width : window width (윈도우 폭)\n            # 여기서는 -125 ~ 225 사이의 구간만 명암을 세밀하게 표현한다. \n            center, width = (40,350)\n            \n            return center, width\n            # return \"CT\",\"CT\"\n        elif modality =='MR':\n            return None, None, # MR 영상은 윈도잉 없이 통계적 정규화만 할 것 ! \n    \n        else:\n            return None,None \n    \n    '''\n    Extract 2D pixel array from DICOM \n    input : ds\n    output : 한 파일에 여러 슬라이스가 있을 경우, 즉 3D일 경우 가운데 슬라이스 선택, 컬러일경우 grayscale로 변경, 이 후 HU단위로 변경 적용 후 img 반환 \n    '''\n    \n    def extract_pixel_array(self, ds):\n        img = ds.pixel_array.astype(np.float32)\n    \n        # For 3D volume case (multiple frame ) - select middle frame\n        if img.ndim == 3:\n            frame_idx = img.shape[0] // 2\n            img = img[frame_idx]\n            print(f\"Selected frame {frame_idx} from 3D DICOM\")\n        \n        # Convert color image to grayscale\n        # img.shape[-1] 이미지의 마지막 차원의 크기 가져오기 \n        if img.ndim ==3 and img.shape[-1]==3:\n            img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2GRAY).astype(np.float32)\n            # print(\"Converted color image to grayscale\")\n    \n        '''\n        Apply RescaleSlope and RescaleIntercept \n        DICOM 파일은 저장공간과 호환성 문제로 인해 픽셀 값을 단순한 정수로 저장한다. \n        그러나 실제 의료 영상에서 의미있는 값(HU)을 얻으려면 변환을 해줘야한다.\n        - RescaleSlope ,RescaleIntercept 는 DICOM 헤더에 저장된 선형 변환 계수이다.\n        - 실제 물리적 단위로 변환하는 공식 : \n            Image value = (RescaleSlope) * (Stored value) + RescaleIntercept\n        - 이 변환을 적용하지 않으면, 영상의 밝기와 대조가 실제의 물리적 특성을 반영하지 못한다.\n        예를 들어서 CT에서 물은 HU = 0, 공기는 HU = -1000, 뼈는 HU = 400~ 1000등으로 구분되는데, 변환하지 않으면 이런 구분이 불가능하다.\n        \n        ''' \n        slope = getattr(ds, 'RescaleSlope',1)\n        intercept = getattr(ds,'RescaleIntercept',0)\n        if slope != 1 or intercept != 0:\n            img = img * float(slope) + float(intercept)\n            # print(f\"Applied rescaling: slope={slope}, intercept={intercept}\")\n    \n        return img\n    \n    '''\n    Apply windowing or statistical normalization\n    input : img, window_center, window_width\n    output : CT - windowing, MRI - normalization 적용 후 uint8로 변환 후 반환 \n    \n    '''\n    def apply_windowing_or_normalize(self,img,center,width):\n        if center is not None and width is not None :\n    \n            # 전통적 방식의 CT windowing\n            # Windowing processing (for CT/CTA)\n            img_min = center - width / 2\n            img_max = center + width / 2\n    \n            windowed = np.clip(img, img_min, img_max)\n             # 값들을 0과 1 사이로 재조정\n            windowed = (windowed-img_min) / (img_max - img_min + 1e-7)\n            result = (windowed*255).astype(np.uint8)\n            # print(f\"Applied windowing: [{img_min:.1f}, {img_max:.1f}] → [0, 255]\")\n            return result\n        \n        else : # z-score normalization(for MR)\n            mean = np.mean(img)\n            std = np.std(img)\n    \n            normalized = (img - mean) / (std + 1e-7) \n            result = (normalized*255).astype(np.uint8)\n            # print(f\"Applied normalization: [{mean:.1f}, {std:.1f}] → [0, 255]\")\n            return result \n            \n            \n    '''\n    Resize 3D volumn to target size\n    '''\n    def resize_volume_3d(self, volume):\n        current_shape = volume.shape\n        target_shape = (self.target_depth,self.target_height, self.target_width)\n        if current_shape == target_shape:\n    \n            return volume\n    \n        else:\n            # 3D resizing using scipy.ndimage\n            # 각 축별로 얼마나 확대/축소할 지 비율을 계산\n            zoom_factors = [target_shape[i] / current_shape[i] for i in range(3)]\n    \n            # resize with linear interpolation\n            resized_volume = ndimage.zoom(volume, zoom_factors, order = 1, mode='nearest')\n    \n            # 리사이즈 후 shape이 목표보다 클 수 있으므로 슬라이싱으로 정확한 목표 shape에 맞춘다.\n            resized_volume = resized_volume[:self.target_depth, :self.target_height, :self.target_width]\n    \n            # 필요한 경우 패딩 추가 \n    \n            # uint8 타입(0~255 범위)으로 변환해서 반환 -> \n            return resized_volume.astype(np.uint8)\n\n    '''\n    Process DICOM series and return as Numpy array (for Kaggle : no file saving)\n    '''\n    def process_series(self,series_path):\n        try:\n            datasets, series_name = self.load_dicom_series(series_path)\n\n            # Check first DICOm to determine 2D/3D \n            # 3D 볼륨인지, 2D 슬라이스인지 확인하기 \n            first_ds = datasets[0]\n            first_img = first_ds.pixel_array\n\n            # DICOM 파일이 1개이고 그 안에 여러 프레임(3D)이 있으면 3D DICOM으로 처리한다. \n            if len(datasets)==1 and first_img.ndim == 3:\n                # 1. Single 3D DICOM file\n                return self._process_single_3d_dicom(first_ds, series_name)\n            else:\n                # 2. Multiple 2D DICOM files\n                # 여러 개의 2D 파일 슬라이스가 있으면 각각을 읽어서 3D 볼륨을 쌓는 방식으로 처리한다.\n                return self._process_multiple_2d_dicoms(datasets, series_name)\n        # 파일을 읽거나 처리 중 오류가 발생하면 예외를 발생시킨다.\n        except Exception as e:\n            print(f\"Failed to process series {series_path}: {e}\")\n            raise \n\n    '''\n    Process single 3D DICOM file(for kaggle : no file saving)\n    한 파일에 여러 슬라이스가 들어있는 CT/MRI를 전처리하여 3D numpy 배열로 반환하는 함수 \n    '''\n    def _process_single_3d_dicom(self, ds, series_name):\n        # get pixel array\n        volume = ds.pixel_array.astype(np.float32)\n        # print(f'volume.shape : {volume.shape}')\n\n        # Apply RescaleSlope and RescaleIntercept\n\n        slope = getattr(ds, 'RescaleSlope',1)\n        intercept = getattr(ds,'RescaleIntercept',0)\n\n        if slope != 1 or intercept != 0:\n            volume = volume * float(slope) + float(intercept)\n            #print(f\"Applied rescaling: slope={slope}, intercept={intercept}\")\n\n        \n        # Get windowing settings\n        window_center,  window_width = self.get_windowing_params(ds)\n\n        # Apply windowing to each slice\n        processed_slices = []\n\n        print(f'volume.shape : {volume.shape}')\n\n        for i in range(volume.shape[0]): # 여기서 volumn.shape의 결과와 순서는 ?\n            slice_img = volume[i]\n            processed_img = self.apply_windowing_or_normalize(slice_img, window_center, window_width)\n            processed_slices.append(processed_img)\n            del slice_img, processed_img\n        gc.collect()\n\n        volume = np.stack(processed_slices, axis = 0)\n        print(f\"3D volume shape after windowing: {volume.shape}\")\n        del processed_slices\n        gc.collect()\n\n        # 3D resize\n        final_volume = self.resize_volume_3d(volume)\n        del volume\n        gc.collect()\n        \n        print(f\"Successfully processed 3D DICOM series {series_name}\")\n        return final_volume\n    \n    '''\n    Process multiple 2D dicom files\n    '''\n\n    def _process_multiple_2d_dicoms(self, datasets,series_name):\n        slice_info = self.extract_slice_info(datasets) # extract_slice_info : slice의 i, instance_number, z_position 등을 담은 slice_info 리스트를 반환한다. \n        sorted_slices = self.sort_slices_by_position(slice_info) # sort_slices_by_position : slice_info 리스트를 받아서 'z_position'을 기준으로 정렬 후 정렬된 리스트 반환 \n        first_img = self.extract_pixel_array(sorted_slices[0]['dataset']) # 첫번 째 슬라이스를 통해서 \n        window_center, window_width = self.get_windowing_params(sorted_slices[0]['dataset'], first_img)\n        processed_slices = []\n\n        for slice_data in sorted_slices:\n            ds = slice_data['dataset']\n            img = self.extract_pixel_array(ds)\n            processed_img = self.apply_windowing_or_normalize(img,window_center, window_width)\n            resized_img = cv2.resize(processed_img, (self.target_width, self.target_height))\n            processed_slices.append(resized_img)\n            \n            del ds, img, processed_img, resized_img\n            gc.collect()\n            \n        volume = np.stack(processed_slices, axis = 0) # axis = 0의 의미는? \n        \n        del processed_slices\n        gc.collect()\n        \n        final_volume = self.resize_volume_3d(volume)\n        del volume\n        gc.collect()\n        \n        return final_volume\n    \n        \n    \"\"\"\n    DICOM processing function for Kaggle inference (single series)\n    \n    Args:\n        series_path: Path to DICOM series\n        target_shape: Target volume size (depth, height, width)\n    \n    Returns:\n        np.ndarray: Processed volume\n    \"\"\"\ndef process_dicom_series_kaggle(series_path, target_shape = (32,384,384)):\n    preprocessor = DICOMPreprocessor(target_shape = target_shape)\n    return preprocessor.process_series(series_path)\n        \n\n    '''\n    Safe DICOM processing with memory cleanup\n    '''\ndef process_dicom_series_safe(series_path, target_shape = (32,384,384)):\n    try:\n        volume = process_dicom_series_kaggle(series_path, target_shape)\n        return volume\n    finally:\n        # memory cleanup\n        gc.collect()\n\n    '''\n    Test function \n    - Text processing for single series\n    '''\ndef test_single_series(series_path, target_shape = (32, 384, 384)):\n    try:\n        print(f'process_Dicom_seires호출 : {series_path}')\n        volume = process_dicom_series_safe(series_path, target_shape)\n        print(f'test_single_series : {volume.shape}')\n        return volume\n    except Exception as e:\n        print(f\"✗ Failed to process series: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:36:56.027505Z","iopub.execute_input":"2025-10-13T15:36:56.028020Z","iopub.status.idle":"2025-10-13T15:36:56.052221Z","shell.execute_reply.started":"2025-10-13T15:36:56.027997Z","shell.execute_reply":"2025-10-13T15:36:56.051611Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"path = os.path.join(SERIES_PATH,'/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647' )\nvolume = test_single_series(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:57:44.635346Z","iopub.execute_input":"2025-10-13T15:57:44.635785Z","iopub.status.idle":"2025-10-13T15:57:44.639386Z","shell.execute_reply.started":"2025-10-13T15:57:44.635762Z","shell.execute_reply":"2025-10-13T15:57:44.638687Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(volume)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:44:17.391958Z","iopub.execute_input":"2025-10-13T15:44:17.392200Z","iopub.status.idle":"2025-10-13T15:44:17.396368Z","shell.execute_reply.started":"2025-10-13T15:44:17.392185Z","shell.execute_reply":"2025-10-13T15:44:17.395782Z"}},"outputs":[{"name":"stdout","text":"(32, 384, 384)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## 전처리하는데 메모리가 부족하다\n- del, gc 활용\n\n## del \n- 변수나 객체에 대한 참조를 삭제한다.\n- 객체의 참조만 끊을 뿐 실제 메모리 해제는 gc가 결정한다.\n### gc\n- 자동으로 해제되지 않는 객체를 수동으로 정리할 수 있게 해준다.\n- gc.collect()를 호출하면 즉시 가비지 컬렉션을 실행하여 더이상 참조되지 않는 객체를 메모리에서 해제한다.","metadata":{}},{"cell_type":"markdown","source":"### 전처리하는데 시간이 너무 오래 걸린다.  -> 병렬 처리 \n- 병렬 처리\n- 병렬 처리해도 append가 잘 될까? ","metadata":{}},{"cell_type":"markdown","source":"DICOM 파일을 더 빠르게 로딩하려면 **병렬 처리(멀티스레딩/멀티프로세싱)**를 활용하는 것이 가장 효과적입니다.  \npydicom의 dcmread는 순차적으로 파일을 읽으면 느릴 수 있으나, 여러 파일을 동시에 읽으면 I/O 대기 시간을 줄일 수 있습니다.\n\n***\n\n### 병렬 처리 예시 (concurrent.futures 사용)\n\n아래는 Python의 `concurrent.futures.ThreadPoolExecutor`를 사용해 DICOM 파일을 병렬로 읽는 코드 예시입니다.\n\n```python\nimport concurrent.futures\nimport pydicom\n\ndef safe_dcmread(filepath):\n    try:\n        return pydicom.dcmread(filepath)\n    except Exception as e:\n        print(f\"Failed to load {filepath}: {e}\")\n        return None\n\ndef load_dicom_series_parallel(dicom_files):\n    datasets = []\n    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n        results = list(executor.map(safe_dcmread, dicom_files))\n    # None이 아닌 것만 필터링\n    datasets = [ds for ds in results if ds is not None]\n    return datasets\n\n# 기존 코드에서\ndatasets = load_dicom_series_parallel(dicom_files)\nif not datasets:\n    raise ValueError(f\"No valid DICOM files in {series_path}\")\nreturn datasets, series_name\n```\n\n- `max_workers=8`은 CPU 코어 수에 맞게 조정 가능 (8~16 추천)\n- 실패한 파일은 None으로 반환, 이후 필터링\n\n***\n\n### 추가 팁\n\n- **멀티프로세싱**(ProcessPoolExecutor)도 가능하지만, pydicom 객체는 프로세스 간 공유가 어려울 수 있으니 ThreadPoolExecutor가 더 간단합니다.\n- SSD 환경에서 병렬 I/O 효과가 더 큽니다.\n- tqdm 등으로 진행률 표시도 추가 가능\n\n***\n\n### 요약\n\n- DICOM 파일 로딩을 병렬화하면 2~4배 이상 속도 향상을 기대할 수 있습니다.\n- 위 코드를 기존 for문 대신 사용하면, 대량의 DICOM 파일을 훨씬 빠르게 읽을 수 있습니다.[1][4]\n\n[1](https://www.reddit.com/r/learnpython/comments/1ez4b7d/what_is_a_better_approach_to_opening_multiple/)\n[2](https://tistory.hu-nie.com/entry/DICOM%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83-2)\n[3](https://bo-10000.tistory.com/60)\n[4](https://www.reddit.com/r/Python/comments/x87oyq/any_trick_to_load_few_big_files_in_python/)\n[5](https://coding-nurse.tistory.com/466)\n[6](https://blog.naver.com/elmidion/221715462333)\n[7](https://89douner.tistory.com/284)","metadata":{}},{"cell_type":"code","source":"'''\nPreprocessing one sereis \n'''\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n\n\ndef preprocess_one_series(sereis_path):\n    try:\n        volume = process_series(series_path)\n        return volume\n    except Exception as e:\n        print(f\"failed to preprocess one sereis : {series_path}\")\n        return None\n\nall_series_id = os.path.basename(series_path)\n\nprint(len(all_series_path))\nresults = []\nwith ProcessPoolExecutor(max_workers= 8) as executor:\n    future_to_path = {executor.submit(preprocess_one_series,path): path for path in all_series_path }\n    for future in as_completed(future_to_path):\n        result = future_result()\n        if result is not None:\n            results.append(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:08.235890Z","iopub.execute_input":"2025-10-13T16:06:08.236560Z","execution_failed":"2025-10-13T16:12:36.793Z"}},"outputs":[{"name":"stdout","text":"1001306\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 아주 간단한 3D CNN 모델 정의하기\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Simple3DCNN(nn.Module):\n     def __init__(self, in_channels=1, num_classes=1):\n            super().__init__()\n            self.conv1 = nn.Conv3d(in_channels, 8, kernel_size=3, padding=1)\n            self.bn1 = nn.BatchNorm3d(8)\n            self.pool1 = nn.MaxPool3d(2)\n    \n            self.conv2 = nn.Conv3d(8, 16, kernel_size=3, padding=1)\n            self.bn2 = nn.BatchNorm3d(16)\n            self.pool2 = nn.MaxPool3d(2)\n    \n            self.fc1 = nn.Linear(16*8*96*96, 64)\n            self.fc2 = nn.Linear(64, num_classes)\n    def forward(self, x):\n        # x: (B, C, D, H, W)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n      \n            \nclass DicomVolumeDataset(torch.utils.data.Dataset):\n    def __init__(self, path_list, labels, preprocessor):\n        self.path_list = path_list\n        self.labels = labels\n        self.preprocessor = preprocessor\n\n    def __len__(self):\n        return len(self.path_list)\n\n    def __getitem__(self, idx):\n        volume = self.preprocessor.process_series(self.path_list[idx])  # (D, H, W)\n        # (D, H, W) → (1, D, H, W)로 reshape해서 모델에 넘김\n        volume = torch.tensor(volume, dtype=torch.float32).unsqueeze(0) / 255.0\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return volume, label\n\n\n# 예시 DICOM 경로와 라벨 리스트\ntrain_paths = list(train_df['SeriesInstanceUID'])   # [\"series_folder1\", \"series_folder2\", ...]\ntrain_labels = list(train_df['Aneurysm Present'])   # [0, 1, ...] (동맥류 유무)\n\npreprocessor = DICOMPreprocessor(target_shape=(32,384,384))\ntrain_data = DicomVolumeDataset(train_paths, train_labels, preprocessor)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Simple3DCNN(in_channels=1, num_classes=1).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in range(3):  # 몇 번 돌려보기\n    model.train()\n    for X, y in train_loader:\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = model(X).squeeze(-1)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n    print(f'epoch {epoch}, loss: {loss.item():.4f}')\n\ndef predict(series_path):\n    model.eval()\n    volume = preprocessor.process_series(series_path)   # (D, H, W)\n    X = torch.tensor(volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0  # (1, 1, D, H, W)\n    X = X.to(device)\n    with torch.no_grad():\n        logits = model(X)\n        prob = torch.sigmoid(logits).item()\n    return prob\n\n'''\nTEST\n'''\n# 예시 사용:\ntest_series_path = train_paths[0:4]\nprint('test predict:', predict(test_series_path))\n\nclass DummyInferenceServer:\n    def __init__(self, predict_fn):\n        self.predict = predict_fn\n\n    def run_local_gateway(self, series_paths):\n        results = []\n        for path in series_paths:\n            result = self.predict(path)\n            results.append({'SeriesInstanceUID': os.path.basename(path), 'Aneurysm Present': result})\n        df = pd.DataFrame(results)\n        print(df)\n        return df\n\n# 서버 객체 생성 및 로컬 테스트\ninference_server = DummyInferenceServer(predict)\n\ndf = inference_server.run_local_gateway(test_series_paths)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:12:55.362025Z","iopub.execute_input":"2025-10-13T16:12:55.362744Z","iopub.status.idle":"2025-10-13T16:12:55.370473Z","shell.execute_reply.started":"2025-10-13T16:12:55.362719Z","shell.execute_reply":"2025-10-13T16:12:55.369579Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_84/1477068832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"],"ename":"NameError","evalue":"name 'results' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"markdown","source":"### 모델을 훈련시켜보자 ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train.csv에서 성별 데이터 1,0으로 변경하기\ntrain_copy = train_df.copy()\n\ntrain_copy['PatientSex'] = train_copy['PatientSex'].map( {'Female' : 0, 'Male' : 1 })\ntrain_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:19:14.138100Z","iopub.execute_input":"2025-10-11T15:19:14.138484Z","iopub.status.idle":"2025-10-11T15:19:14.176361Z","shell.execute_reply.started":"2025-10-11T15:19:14.138456Z","shell.execute_reply":"2025-10-11T15:19:14.175164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\n\nBATCH_SIZE = 4 \nbatch_vols = []\nbatch_series_uids = []\nbatch_sexes = []\nbatch_ages = []\nbatch_labels= []\n\nmodel = Simple3DAneurysmCNN()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = torch.nn.BCEWithLogitsLoss()\nmodel.train()\n\nfor i, series_uid in enumerate(os.listdir(SERIES_PATH)):\n    series_path = os.path.join(SERIES_PATH,series_uid)\n    vol = volumn_from_series(series_path)\n    if vol is None:\n        continue\n\n    # train.csv에서 sex,age 정보 가져오기 \n    row = train_copy[train_copy['SeriesInstanceUID'] == series_uid]\n    if row.empty:\n        continue\n    sex = float(row['PatientSex'].iloc[0]) # 값 추출 \n    age = float(row['PatientAge'].iloc[0]) \n    label = float(row['Aneurysm Present'].iloc[0])\n    \n    batch_vols.append(vol)\n    batch_sexes.append(sex)\n    batch_ages.append(age)\n    batch_labels.append(label)\n    batch_series_uids.append(series_uid)\n\n    # 배치가 찼을 경우 처리\n    if len(batch_vols) == BATCH_SIZE:\n        \n        batch_array = np.stack(batch_vols, axis = 0)\n        '''\n        여기서 batch_vols들이 모두 동일한 shpae이어야 stack할 수 있음\n        '''\n        # 모델 입력 \n        clinical_features = list(zip(batch_sexes, batch_ages))\n\n        # print(f\"torch.from_numpy(batch_array) : {torch.from_numpy(batch_array).shape}\")\n        # torch.Size([4, 32, 384, 384])\n        tensor_image = torch.from_numpy(batch_array).unsqueeze(1).float() \n        #print(f\"tensor_image.shape : {tensor_image.shape}\")\n        # torch.Size([4, 1, 32, 384, 384])\n\n        \n        # print(f\"torch.tensor(clinical_features) : {torch.tensor(clinical_features)}\")\n    \n        tensor_clinical = torch.tensor(clinical_features).float()  # batch 크기 맞춰서 (1,2)\n\n        tensor_labels = torch.tensor(batch_labels).float()\n        tensor_labels = tensor_labels.unsqueeze(1)\n\n        print(f\"tensor_labels : {tensor_labels.shape}\" )\n        \n        # 모델 호출\n        optimizer.zero_grad()\n        outputs = model(tensor_image, tensor_clinical)\n        loss = criterion(outputs, tensor_labels)\n        loss.backward()\n        optimizer.step()\n\n        # 메모리 정리\n        del batch_vols , batch_sexes, batch_ages, batch_series_uids\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n        batch_vols = []\n        batch_sexes = []\n        batch_ages = []\n        batch_labels = []\n        batch_series_uids = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T14:06:20.918607Z","iopub.execute_input":"2025-10-11T14:06:20.919955Z","iopub.status.idle":"2025-10-11T15:02:10.612443Z","shell.execute_reply.started":"2025-10-11T14:06:20.919916Z","shell.execute_reply":"2025-10-11T15:02:10.602903Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ❌ 메모리 부족 문제 발생함 !! \n- Your notebook tried to allocate more memory than is available. It has restarted.\n\n- 배치 단위로 처리할 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"### batch_array = np.stack(batch_vols, axis = 0) 에서 발생\n- all input arrays must have the same shape\n\n- volumn shape가 vol.shape : (1, 25, 528, 528) 인 것이 있음\n\n- 왜 4차원인게 있는거지??","metadata":{}},{"cell_type":"markdown","source":"### 발생 에러\n- vol = np.stack(slices, axis=0) -> ValueError: need at least one array to stack","metadata":{}},{"cell_type":"markdown","source":"### 이제 Dicom 이미지를 series별 volumn을 생성함 \n- 이제 train.csv를 통해 동맥류 여부를 예측하는 모델을 만들어보자","metadata":{}},{"cell_type":"code","source":"'''\n매우 간단한 3D CNN 모델 \n'''\nimport torch, torch.nn as nn\nclass Simple3DAneurysmCNN(nn.Module):\n    def __init__(self, num_classes=1, num_clinical_features = 2):\n        super().__init__()\n\n        # 이미지 경로 \n        self.conv1 = nn.Conv3d(1,8,kernel_size = 3, padding= 1)\n        self.relu = nn.ReLU()\n        self.pool = nn.AdaptiveAvgPool3d((1,1,1))\n        self.fc_img = nn.Linear(8, 16)\n\n        # 임상 정보 경로\n        self.fc_clinical = nn.Linear(num_clinical_features, 8)\n\n        # 이미지 + 임상 정보 합친 후 최종 분류\n        self.fc_combined = nn.Linear(16 + 8, num_classes)\n    \n    def forward(self,x_img, x_clinical):\n        # 이미지 처리 \n        x= self.relu(self.conv1(x_img))\n        x= self.pool(x)\n        x = x.view(x.size(0),-1)\n        img_feat = self.fc_img(x)\n\n        # 임상 정보 처리 \n        clin_feat = self.relu(self.fc_clinical(x_clinical))\n\n        # 두 경로 합치기 \n        combined = torch.cat([img_feat, clin_feat], dim=1)\n        out = torch.sigmoid(self.fc_combined(combined))\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:19:30.633351Z","iopub.execute_input":"2025-10-11T15:19:30.633754Z","iopub.status.idle":"2025-10-11T15:19:30.642558Z","shell.execute_reply.started":"2025-10-11T15:19:30.633709Z","shell.execute_reply":"2025-10-11T15:19:30.641395Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset 클래스 생성 ","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass RSNA_Dataset(Dataset):\n    def __init__(self,df):\n        self.df = df\n        self.series_root_path = SERIES_PATH\n        self.series_uids = df['SeriesInstanceUID']\n\n    def __len__(self):\n        return len(self.series_uids)\n        \n    def __getitem__(self, idx):\n        series_uid = self.series_uids[idx]\n        series_path = f\"{self.series_root_path}/{series_uid}\"\n\n        volume = volumn_from_series(series_path)\n\n        row = self.df[self.df['SeriesInstanceUID']==series_uid]\n        sex = float(row['PatientSex'])\n        age = float(row['PatientAge'])\n        labels = float(row['Aneurysm Present'])\n\n\n        tensor_image = torch.from_numpy(volume).unsqueeze(0).float()\n        tensor_clinical = torch.tensor([sex, age]).float()\n        tensor_label = torch.tensor(labels).float()\n\n        return tensor_image, tensor_clinical , tensor_label\n         ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:32:47.424305Z","iopub.execute_input":"2025-10-11T15:32:47.424701Z","iopub.status.idle":"2025-10-11T15:32:47.434568Z","shell.execute_reply.started":"2025-10-11T15:32:47.424678Z","shell.execute_reply":"2025-10-11T15:32:47.433525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = RSNA_Dataset(train_copy)\nval_dataset = RSNA_Dataset(val_df)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 4, shuffle= True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size = 4, shuffle= True,pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:32:53.297945Z","iopub.execute_input":"2025-10-11T15:32:53.298327Z","iopub.status.idle":"2025-10-11T15:32:53.305066Z","shell.execute_reply.started":"2025-10-11T15:32:53.298271Z","shell.execute_reply":"2025-10-11T15:32:53.303999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Simple3DAneurysmCNN()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = torch.nn.BCELoss()\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n    \n    model.train()\n    for images, clinicals, labels in train_loader:\n        labels = labels.unsqueeze(1)\n        print(train_loader)\n        optimizer.zero_grad()\n        outputs = model(images, clinicals)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n   \n    model.eval()\n    with torch.no_grad():\n        total_correct = 0\n        total = 0\n        for images, clinicals, labels in val_loader:\n            outputs = model(images, clinicals)\n            preds = (outputs > 0.5).float()\n            total_correct += (preds == labels).sum().item()\n            total += preds.numel()\n\n        accuracy = total_correct / total\n        print(f\"Epoch {epoch+1} Validation Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:32:54.808686Z","iopub.execute_input":"2025-10-11T15:32:54.809063Z","iopub.status.idle":"2025-10-11T15:33:04.617450Z","shell.execute_reply.started":"2025-10-11T15:32:54.809038Z","shell.execute_reply":"2025-10-11T15:33:04.615876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 모델의 정확도를 확인해보자 \n- 모델의 예측값과 정답을 비교하기 ","metadata":{}},{"cell_type":"code","source":"model.eval() # 모델 평가 모드 \n\nwith torch.no_grad():\n    total_correct = 0\n    total = 0\n    for images, clinicals, labels in val_loader:\n        outputs = model(images,clinicals)\n        preds = (outputs >0.5).float()\n        total_correct += (preds == labels).sum().item()\n        total += preds.numel()\n    accuracy = total_correct / total\nprint(f\"Epoch {epoch+1} Validation Accuracy: {accuracy:.4f}\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:25:31.313245Z","iopub.status.idle":"2025-10-11T15:25:31.313551Z","shell.execute_reply.started":"2025-10-11T15:25:31.313421Z","shell.execute_reply":"2025-10-11T15:25:31.313434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_3d_array(series_uid):\n    # 시리즈 폴더 경로\n    series_path_uid = os.path.join(SERIES_PATH,series_uid)\n    \n    # DICOM 파일 이름 추출 후 정렬 (InstanceNumber 또는 FileName 기반 정렬)\n\n    # os.listdir(series_path_uid) # 해당 디렉토리 내의 모든 파일과 디렉토리 리스트를 리턴한다. \n    \n    dcm_files = [f for f in os.listdir(series_path_uid)]\n    \n    # # 인스턴스 번호 기준 정렬 (선택적)\n    # dcm_files.sort(key=lambda x: pydicom.dcmread(os.path.join(series_path, x)).InstanceNumber)\n    \n    # 모든 DICOM 읽기\n    slices = [pydicom.dcmread(os.path.join(series_path_uid, f)) for f in dcm_files]\n\n    print(slices[0].ImagePositionPatient)\n    print('Voxelsize', slices[0].Get)\n    \n    # 3D 배열 생성 (shape: z, y, x)\n    volume = np.stack([s.pixel_array for s in slices], axis=0)\n    \n    # print(volume.shape)  # (슬라이스 수, y크기, x크기)\n    return volume","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.261993Z","iopub.status.idle":"2025-10-11T13:58:24.262320Z","shell.execute_reply.started":"2025-10-11T13:58:24.262165Z","shell.execute_reply":"2025-10-11T13:58:24.262178Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### XYZ <-> IR2 함수","metadata":{}},{"cell_type":"code","source":"IrcTuple = collections.namedtuple('IrcTuple',['index','row','col'] )\nXyzTuple = collections.namedtuple('XyzTuple',['x','y','z'])\n\n'''\ncoord_irc : xyz로 변환하려는 irc 좌표\ncoord_xyz : irc로 변환하려는 xyz 좌표\norigin_xyz:  dicom_image.GetOrigin() \nvxSize_xyz :  dicom_image.GetSpacing()\ndirection_a: dicom_image.GetDicrection()\n'''\ndef irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n    cri_a = np.array(coord_irc)[::-1]\n    # IRC 좌표 (I, R, C)를 (C, R, I) 순서로 바꾸어 cri_a에 저장\n    origin_a = np.array(origin_xyz)\n    vxSize_a = np.array(vxSize_xyz)\n    coords_xyz = (direction_a @  (cri_a *vxSize_a )) + origin_a\n    return XyzTuple(*coords_xyz)\n\ndef xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n    origin_a = np.array(origin_xyz)\n    vxSize_a = np.array(vxSize_xyz)\n    coord_a = np.array(coord_xyz)\n    cri_a = ( (coord_a-origin_a) @ np.linalg.inv(direction_a)) / vxSize_a\n    cri_a = np.round(cri_a)\n    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0])) # z,y,x로 반환","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.264216Z","iopub.status.idle":"2025-10-11T13:58:24.264579Z","shell.execute_reply.started":"2025-10-11T13:58:24.264436Z","shell.execute_reply":"2025-10-11T13:58:24.264453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 이미지 클래스 정의하기","metadata":{}},{"cell_type":"markdown","source":"- glob.glob(pattern) : 주어진 경로 패턴에 맞는 모든 파일 경로를 리스트로 반환한다.\n- data-unversioned/part2/luna/subset*/{}.mhd : data-unversioned/part2/luna/ 폴더 내에서 subset으로 시작하는 모든 서브 폴더가 대상 \n- {}.mhd'.format(series_uid) : 그 폴더 내에서 series_uid.mhd 파일을 찾음\n- [0] : 찾은 파일 중 첫 번째 결과만 취함\n","metadata":{}},{"cell_type":"markdown","source":"## Image를 담을 클래스 정의","metadata":{}},{"cell_type":"code","source":"class ImageClass:\n    def __init__(self, series_uid, sod_uid):\n        dcm_dir_path = glob.glob(\n            SERIES_PATH +'/{}'.format(series_uid)       \n        )[0]\n\n        dcm_path = glob.glob(\n            dcm_dir_path+\"/{}.dcm\".format(sod_uid)\n        )[0]\n        \n        dcm_image = sitk.ReadImage(dcm_path)\n        dcm_a = np.array(sitk.GetArrayFromImage(dcm_image), dtype= np.float32)\n\n        # hu \n        dcm_a.clip(-1000, 1000, dcm_a)\n\n        self.series_uid= series_uid\n        self.sod_uid = sod_uid\n        self.hu_a = dcm_a\n        self.origin_xyz = XyzTuple(*dcm_image.GetOrigin())\n        self.vxSize_xyz = XyzTuple(*dcm_image.GetSpacing())\n        self.direction_a = np.array(dcm_image.GetDirection()).reshape(3,3)\n    '''\n3D 영상 데이터에서 주어진 중심 좌표(center_xyz)를 배열 인덱스 좌표(IRC)로 변환하고,\n그 주변의 일정 크기(width_irc)로 잘라낸 작은 3D 조각(chuck)을 반환하는 함수\n- 여기서 우리 타깃 동맥류가 잘 잘릴까? \n'''\n    def getRawCandidate(self,center_xyz, width_irc):\n        center_irc = xyz2irc(center_xyz, self.origin_xyz,\n                            self.vxSize_xyz, self.direction_a)\n        slice_list = []\n        for axis, center_val in enumerate(center_irc):\n            start_ndx = int(round(center_val - width_irc[axis]/2))\n            end_ndx = int(start_ndx + width_irc[axis])\n            assert center_val >= 0 and center_val < self.hu_a.shape[axis], repr([self.series_uid, center_xyz, self.origin_xyz, self.vxSize_xyz, center_irc, axis])\n            if start_ndx < 0:\n                    # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n                    #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n                    start_ndx = 0\n                    end_ndx = int(width_irc[axis])\n    \n            if end_ndx > self.hu_a.shape[axis]:\n                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n                end_ndx = self.hu_a.shape[axis]\n                start_ndx = int(self.hu_a.shape[axis] - width_irc[axis])\n    \n                slice_list.append(slice(start_ndx, end_ndx))\n    \n            ct_chunk = self.hu_a[tuple(slice_list)]\n    \n            return ct_chunk, center_irc\n\ndef getImage(series_uid, sod_uid):\n    return ImageClass(series_uid,sod_uid)\n    \n    \ndef getImageRawCandidate(series_uid, sod_uid, center_xyz, width_irc):\n    image = getImage(series_uid,sod_uid)\n    image_chunk, center_irc = image.getRawCandidate(center_xyz,width_irc)\n    return image_chunk,center_irc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.265921Z","iopub.status.idle":"2025-10-11T13:58:24.266240Z","shell.execute_reply.started":"2025-10-11T13:58:24.266074Z","shell.execute_reply":"2025-10-11T13:58:24.266085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 테스트 \nimg = Image('1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647',\n           '1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450')\n\nprint(img.vxSize_xyz)\nprint(img.origin_xyz)\nprint(img.direction_a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.268374Z","iopub.status.idle":"2025-10-11T13:58:24.268796Z","shell.execute_reply.started":"2025-10-11T13:58:24.268573Z","shell.execute_reply":"2025-10-11T13:58:24.268592Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_3d_array('1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.269527Z","iopub.status.idle":"2025-10-11T13:58:24.269858Z","shell.execute_reply.started":"2025-10-11T13:58:24.269672Z","shell.execute_reply":"2025-10-11T13:58:24.269684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CandidateInfoTuple\nCandidateInfoTuple = collections.namedtuple('CandidateInfoTuple',\n                                series_uid, sop_uid, center_xyz')","metadata":{}},{"cell_type":"code","source":"import ast \n### 2D dicom image를 3D array로 불러오기 \n\n'''\n여기 코드 에러 있음 ** ,  series_uid만 다르고 다른 항목 데이터 모두 동일함 \n'''\n\n# 전체 데이터셋에서 후보 동맥류 정보 리스트를 만드는 함수 \ndef getCandidateInfoList():\n\n    # 동맥류가 있는 위치 : 정답 동맥류 \n    localizers_dict = {}\n    candidateInfo_list = []\n    with open('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv','r') as f:\n        for row in list(csv.reader(f))[1:]: # 인덱스 0에는 열 이름이 있다.그래서 값은 1행부터 있음\n            series_uid = row[0] \n            sop_instance_uid = row[1]\n            z_value = get_z_position(row)\n            data = ast.literal_eval(row[2]) # str을 딕셔너리로 변환하기 \n            xyz = tuple([data['x'], data['y'],z_value])\n            localizers_dict.setdefault(series_uid, []).append(\n                CandidateInfoTuple(True, series_uid, sop_instance_uid, xyz )\n            )\n\n    # train_data 보기 \n    with open('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv','r') as f:\n        for row in list(csv.reader(f))[1:]:\n            is_aneurysm_present = bool(int(row[17]))\n            \n            for localizer in localizers_dict.get(series_uid, []):\n                if row[0] == localizer.series_uid:\n                    xyz = localizer.center_xyz\n                    series_uid = localizer.series_uid\n                    sop_uid = localizer.sop_uid\n                    candidateInfo_list.append(CandidateInfoTuple(\n                        is_aneurysm_present,\n                        series_uid,\n                        sop_uid,\n                        xyz\n                    ))\n                else:\n                    continue\n\n    return candidateInfo_list\n\ndef get_z_position(row):\n    \n    # series에서 seris_uid에 맞는 series 폴더 찾기\n    # series폴더에서 sop_uid 슬라이스 찾기\n    # 해당 슬라이스가 몇 번째 인지 알기 \n    series_folder = os.path.join(SERIES_PATH, row[0])\n    series_image = os.path.join(series_folder, row[1]+'.dcm')\n    with open (series_image,'rb') as f: # 'rb'로 열어야함 \n        ds = pydicom.dcmread(f)\n        # InstanceNumber , DICOM 파일 내에서 해당 슬라이스가 시리즈 내에서 몇 번째 위치하는지를 의미함.\n        if 'ImagePositionPatient' in ds:\n            z_value = ds.ImagePositionPatient[2]            \n        # except AttributeError: # 해당 Dicom 파일에 ImagePositionPatient가 아예없는 경우 발생 \n        #     print(series_image+'\\n')\n        else:   \n            # MR인 경우 에러 발생함. \n            error_ds = ds\n            z_value = 0.0\n        return z_value\n        \n\n\ndef display_image(array):\n    \"\"\"\n    3D Numpy 배열을 슬라이서 위젯을 사용하여 표시 \n    \"\"\"\n    # 슬라이드를 사용하여 슬라이스를 스크롤 \n    def view_image(slice_index):\n        plt.figure(figsize = (10,10)) # 이미지를 표시할 Figure를 설정\n        plt.imshow(array[slice_index], cmap='gray') # 현재 슬라이스 이미지를 회색조로 표시 \n        plt.title(f'Slice {slice_index}') # 슬라이스 번호를 제목으로 설정\n        plt.show() # 이미지를 출력\n    # 슬라이더 생성\n    slice_slider = widgets.IntSlider(min=0, max= array.shape[0]-1, step = 1, description='Slice:')\n    \n    widgets.interact(view_image, slice_index = slice_slider)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.271190Z","iopub.status.idle":"2025-10-11T13:58:24.271495Z","shell.execute_reply.started":"2025-10-11T13:58:24.271371Z","shell.execute_reply":"2025-10-11T13:58:24.271382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"candidateInfo_list = getCandidateInfoList()\npositiveInfo_list = [x for x in candidateInfo_list if x[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.272441Z","iopub.status.idle":"2025-10-11T13:58:24.272682Z","shell.execute_reply.started":"2025-10-11T13:58:24.272567Z","shell.execute_reply":"2025-10-11T13:58:24.272577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"candidateInfo_list[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.274456Z","iopub.status.idle":"2025-10-11T13:58:24.275036Z","shell.execute_reply.started":"2025-10-11T13:58:24.274825Z","shell.execute_reply":"2025-10-11T13:58:24.274845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"positiveInfo_list[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.276233Z","iopub.status.idle":"2025-10-11T13:58:24.277041Z","shell.execute_reply.started":"2025-10-11T13:58:24.276828Z","shell.execute_reply":"2025-10-11T13:58:24.276864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(positiveInfo_list)) # 1863","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.279027Z","iopub.status.idle":"2025-10-11T13:58:24.279373Z","shell.execute_reply.started":"2025-10-11T13:58:24.279218Z","shell.execute_reply":"2025-10-11T13:58:24.279232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## RSNA Dataset Class 정의","metadata":{}},{"cell_type":"code","source":"class RSNADataSet(Dataset):\n    def __init__(self, vel_sride = 0, isValSet_bool = None, series_uid=None):\n        self.candidateInfo_list = copy.copy(getCandidateInfoList())\n        if series_uid:\n            self.candidateInfo_list = [ x for x in self.candidateInfo_list if x.series_uid == series_uid]\n    def __len__(self):\n        return len(self.candidateInfo_list)\n    def __getitem__(self,ndx):\n        candidateInfo_tup = self.candidateInfo_list[ndx]\n        width_irc = (32,48,48)\n\n        candidate_a, center_irc = getImageRawCandidate(\n            candidateInfo_tup[1],\n            candidateInfo_tup[2],\n            candidateInfo_tup[3],\n            width_irc\n        )\n        candidate_t = torch.from_numpy(candidate_a)\n        candidate_t = candidate_t.to(torch.float32)\n\n        pos_t = torch.tensor([\n            not candidateInfo_tup.is_aneurysm_present,\n            candidateInfo_tup.is_aneurysm_present\n        ], dtype = torch.long,)\n\n        return (\n            candidate_t,\n            pos_t,\n            candidateInfo_tup.series_uid,\n            torch.tensor(center_irc),\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.280569Z","iopub.status.idle":"2025-10-11T13:58:24.281373Z","shell.execute_reply.started":"2025-10-11T13:58:24.281207Z","shell.execute_reply":"2025-10-11T13:58:24.281225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"RSNADataSet()[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.282124Z","iopub.status.idle":"2025-10-11T13:58:24.282438Z","shell.execute_reply.started":"2025-10-11T13:58:24.282317Z","shell.execute_reply":"2025-10-11T13:58:24.282329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_localizers.info()\n# trian 데이터에서 동맥류가 있는 환자는 1863명 있는데 왜 여기는 총 데이터가 2254개이지?\n# 여기서 1863은 동맥류가 하나 이상 있는 환자 수이다. \n# train_localizers 에는 동맥류 각각의 위치 좌표를 나타낸다. \n\ntrain_localizers.SeriesInstanceUID.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.284261Z","iopub.status.idle":"2025-10-11T13:58:24.286894Z","shell.execute_reply.started":"2025-10-11T13:58:24.286681Z","shell.execute_reply":"2025-10-11T13:58:24.286703Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train[\"Aneurysm Present\"].sum()  # 1863","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.287676Z","iopub.status.idle":"2025-10-11T13:58:24.287984Z","shell.execute_reply.started":"2025-10-11T13:58:24.287855Z","shell.execute_reply":"2025-10-11T13:58:24.287868Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  값 :\n- ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery', 'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery', 'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery', 'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery', 'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery', 'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present']\n\n- ['1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647', '64', 'Female', 'MRA', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']","metadata":{}},{"cell_type":"markdown","source":"### Simpleitk를 활용한 간단한 이미지 처리 Crop","metadata":{}},{"cell_type":"markdown","source":"##  Histogram Equalization \n\n- 이미지의 대비를 향상시키기 위해 사용 : 이미지의 밝기 분포를 조정하여 어두운부분과 밝은 부분의 대비를 더 명확하게 만든다.\n- 각 픽셀의 밝기 값을 조정하여 히스토그램의 분포를 균일하게 만드는 프로세스\n- 이렇게 하면 어두운 영역에서 세부 정보를 더 잘 볼 수 있게 되어 이미지의 시각적 품질이 향상된다. ","metadata":{}},{"cell_type":"code","source":"# 라이브러리 불러오기 \n\nimport cv2\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.289361Z","iopub.status.idle":"2025-10-11T13:58:24.289674Z","shell.execute_reply.started":"2025-10-11T13:58:24.289539Z","shell.execute_reply":"2025-10-11T13:58:24.289555Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 이미지 불러오기 \n\n\nimg_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\nds = pydicom.dcmread(img_path)\nimg = ds.pixel_array\n\n# 히스토그램 평탄화\n\nimg.dtype # dtype('int16')\nif img.dtype != 'uint8':\n    img = cv2.convertScaleAbs(img, alpha = (255.0/img.max()))\n\ndst = cv2.equalizeHist(img)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.290681Z","iopub.status.idle":"2025-10-11T13:58:24.290992Z","shell.execute_reply.started":"2025-10-11T13:58:24.290868Z","shell.execute_reply":"2025-10-11T13:58:24.290880Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 히스토그램 평탄화 전 후 plot 비교\nplt.figure(figsize = (20,10))\nplt.subplot(1,2,1)\nplt.imshow(img, cmap = 'gray')\nplt.subplot(1,2,2)\nplt.imshow(dst, cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.292186Z","iopub.status.idle":"2025-10-11T13:58:24.292488Z","shell.execute_reply.started":"2025-10-11T13:58:24.292330Z","shell.execute_reply":"2025-10-11T13:58:24.292344Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CLAHE (Contrast Limited Adaptive Histogram Equalization)\n\n- Histogram Equalization은 원본 이미지의 전체에 대한 균일화를 진행하기 떄문에 밝아지지 않아도 될 부분이 밝아지거나 , 원래의 형태나 형테를 알아보기 힘든 경우가 발생할 수 있음.\n\n- 이를 개선할 수 있는 방법이 CLAHE 방법이다.\n\n- 이미지를 작은 블록으로 나누고, 각 블록에 대해 히스토그램 평활화를 개별적으로 적용한다.","metadata":{}},{"cell_type":"code","source":"# 라이브러리 불러오기 \nimport cv2\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-10-11T13:58:24.293969Z","iopub.status.idle":"2025-10-11T13:58:24.294293Z","shell.execute_reply.started":"2025-10-11T13:58:24.294120Z","shell.execute_reply":"2025-10-11T13:58:24.294135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CLAHA 객체 생성 및 적용 \n\n# 이미지 불러오기 \n\n# CLAHE 객체 생성\nclahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize=(12,12))\n\nimg2 = clahe.apply(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.295826Z","iopub.status.idle":"2025-10-11T13:58:24.296849Z","shell.execute_reply.started":"2025-10-11T13:58:24.296614Z","shell.execute_reply":"2025-10-11T13:58:24.296635Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 히스토그램 평탄화 전 후 plot 비교\n\nplt.figure(figsize = (20,10))\nplt.subplot(1,3,1).imshow(img, cmap='gray')\nplt.subplot(1,3,2).imshow(dst, cmap='gray')\nplt.subplot(1,3,3).imshow(img2, cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.298180Z","iopub.status.idle":"2025-10-11T13:58:24.298523Z","shell.execute_reply.started":"2025-10-11T13:58:24.298367Z","shell.execute_reply":"2025-10-11T13:58:24.298384Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Image Normalization\n","metadata":{}},{"cell_type":"markdown","source":"### Min-Max Normalization\n- 데이터의 최솟값과 최댓값을 활용하여 데이터를 일반화하므로 데이터의 분포가 완전히 바뀌지는 않지만, 일정한 범위로 조절된다. ","metadata":{}},{"cell_type":"code","source":"# 이미지 불러오기 \nimg_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\nds = pydicom.dcmread(img_path)\nimg = ds.pixel_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.300677Z","iopub.status.idle":"2025-10-11T13:58:24.301090Z","shell.execute_reply.started":"2025-10-11T13:58:24.300898Z","shell.execute_reply":"2025-10-11T13:58:24.300915Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"min_value = np.min(img)\nmax_value = np.max(img)\n\nnormalized_image = (img - min_value) / (max_value - min_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.302739Z","iopub.status.idle":"2025-10-11T13:58:24.303198Z","shell.execute_reply.started":"2025-10-11T13:58:24.302934Z","shell.execute_reply":"2025-10-11T13:58:24.302951Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualization\n\nplt.figure(figsize = (10,4))\nplt.subplot(1,2,1)\nplt.imshow(img, cmap='gray')\nplt.title('Original Image')\n\nplt.subplot(1,2,2)\nplt.imshow(normalized_image, cmap='gray')\nplt.title('Normalized Image')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.304082Z","iopub.status.idle":"2025-10-11T13:58:24.304366Z","shell.execute_reply.started":"2025-10-11T13:58:24.304243Z","shell.execute_reply":"2025-10-11T13:58:24.304255Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Z-score Normalization\n- 데이터를 평균과 표준 편차를 활용하여 표준화하는 기법이며 데이터의 평균 중심에서 얼마나 떨어져 있는지를 표준 점수로 표현하게 되며, 정규화를 거친 데이터의 평균은 0이 되고 표준 편차는 1이 된다.","metadata":{}},{"cell_type":"code","source":"img_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\nds = pydicom.dcmread(img_path)\nimg = ds.pixel_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.305391Z","iopub.status.idle":"2025-10-11T13:58:24.305634Z","shell.execute_reply.started":"2025-10-11T13:58:24.305518Z","shell.execute_reply":"2025-10-11T13:58:24.305528Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 평균값과 표준 편차를 계산\nmean_value = np.mean(img)\nstd_dev = np.std(img)\n\n# Z-score normalization\nnormalized_sitk_image =  img - mean_value\nnormalized_sitk_image /= std_dev\n\n# 정규화된 이미지를 다시 numpy array로 변환\n# normalized_image_np = sitk.GetArrayFromImage(normalized_sitk_image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.307533Z","iopub.status.idle":"2025-10-11T13:58:24.308041Z","shell.execute_reply.started":"2025-10-11T13:58:24.307842Z","shell.execute_reply":"2025-10-11T13:58:24.307861Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 시각화\n\nplt.figure(figsize = (10,4))\nplt.subplot(1,2,1)\nplt.imshow(img,cmap='gray')\nplt.title('Original Image')\n\nplt.subplot(1,2,2).imshow(normalized_sitk_image, cmap='gray')\nplt.title('Z - Normalized Image')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.309082Z","iopub.status.idle":"2025-10-11T13:58:24.309467Z","shell.execute_reply.started":"2025-10-11T13:58:24.309267Z","shell.execute_reply":"2025-10-11T13:58:24.309293Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 분석 흐름 정리","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os \n\nDATA_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection'\nSERIES_PATH = os.path.join(DATA_PATH,'series')\nSEG_PATH = os.path.join(DATA_PATH,'segmentations')\ntrain_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ntrain_localizers_df = pd.read_csv(os.path.join(DATA_PATH, 'train_localizers.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.310403Z","iopub.status.idle":"2025-10-11T13:58:24.310740Z","shell.execute_reply.started":"2025-10-11T13:58:24.310579Z","shell.execute_reply":"2025-10-11T13:58:24.310595Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- 시리즈 폴더에는 각 환자별 sub폴더가 있고, 각 폴더에 3D 슬라이스 DICOM들이 있다.","metadata":{}},{"cell_type":"markdown","source":"### DICOM을 3D numpy array로 stack하여 읽는 방법","metadata":{}},{"cell_type":"code","source":"# DICOM 폴더 내의 모든 DICOM 파일을 3D 이미지로 읽기\n# load_dicom_series \n\n#DICOM 이미지를 3D Numpy 배열로 변환\n#dicom_to_numpy(dicom_images)\n\n# 3D Numpy 배열을 표시\n#display_image(dicom_array)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.311832Z","iopub.status.idle":"2025-10-11T13:58:24.312198Z","shell.execute_reply.started":"2025-10-11T13:58:24.312035Z","shell.execute_reply":"2025-10-11T13:58:24.312054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 여기서 모든 series에 대해서 수행해야함\n\nseries_folder = os.path.join(SERIES_PATH, str(train_df.loc[0,'SeriesInstanceUID']))\n\n# str(train_df.loc[0,'SeriesInstanceUID'] : train_df의 첫번째 샘플의 id값을 가져온다. \n\n# SeriesInstanceUID 로 DICOM 표준에서 한 시리즈를 고유하게 식별 가능하다! \n\nvol = load_dicom_series(series_folder)\ndicom_array = dicom_to_numpy(vol)\nprint(dicom_array.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.313424Z","iopub.status.idle":"2025-10-11T13:58:24.313774Z","shell.execute_reply.started":"2025-10-11T13:58:24.313587Z","shell.execute_reply":"2025-10-11T13:58:24.313603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame({'A':[1,2,3], 'B':[4,5,6]},index = ['x','y','z'])\n\ndf.iloc[0,1] # 위치로 접근 \ndf.loc['x','B'] # 라벨로 접근","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.315151Z","iopub.status.idle":"2025-10-11T13:58:24.315550Z","shell.execute_reply.started":"2025-10-11T13:58:24.315373Z","shell.execute_reply":"2025-10-11T13:58:24.315390Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 데이터 전처리","metadata":{}},{"cell_type":"code","source":"# 데이터 전처리\nimport cv2\n\n# CLAHE 적용\ndef process_clahe(img):\n    clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize=(12,12))\n    clahe.apply(img)\n    return clahe.apply(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.317165Z","iopub.status.idle":"2025-10-11T13:58:24.317513Z","shell.execute_reply.started":"2025-10-11T13:58:24.317330Z","shell.execute_reply":"2025-10-11T13:58:24.317347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_min_max_normalize(img):\n    min_value = np.min(img)\n    max_value = np.max(img)\n\n    normalized_image = (img - min_value) / (max_value - min_value)\n    return normalized_image\n\ndef process_z_score_normalize(img):\n    mean_value = np.mean(img)\n    std_dev = np.std(img)\n\n    # Z-score normalization\n    normalized_sitk_image =  img - mean_value\n    normalized_sitk_image /= std_dev\n    return normalized_sitk_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.318393Z","iopub.status.idle":"2025-10-11T13:58:24.318739Z","shell.execute_reply.started":"2025-10-11T13:58:24.318532Z","shell.execute_reply":"2025-10-11T13:58:24.318543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.319629Z","iopub.status.idle":"2025-10-11T13:58:24.319916Z","shell.execute_reply.started":"2025-10-11T13:58:24.319789Z","shell.execute_reply":"2025-10-11T13:58:24.319801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nX , y = [],[]\nfor idx, row in train_df.iterrows():\n    series_folder = os.path.join(SERIES_PATH, str(train_df.loc[idx,'SeriesInstanceUID']))\n    files = sorted(os.listdir(series_folder))\n    dcm = pydicom.dcmread(os.path.join(series_folder, files[0]))\n    img = dcm.pixel_array\n   # img = process_min_max_normalize(img)\n    X.append(img)\n    y.append(row['Aneurysm Present'])\nX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.320609Z","iopub.status.idle":"2025-10-11T13:58:24.320968Z","shell.execute_reply.started":"2025-10-11T13:58:24.320788Z","shell.execute_reply":"2025-10-11T13:58:24.320805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Segmentation 데이터 살펴보기\n- /kaggle/input/rsna-intracranial-aneurysm-detection/segmentations\n- nii ","metadata":{}},{"cell_type":"code","source":"\nsegmentation_dir = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations'\ndir = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/1.2.826.0.1.3680043.8.498.10035643165968342618460849823699311381.nii'\nimage = sitk.ReadImage(dir)\nx,y, z =image.GetSize() # (512, 512, 228)\nimage.ImagePositionPatient\n\n# 그러면 train_localizers에서 x,y좌표에 + z좌표를 한후 xyz2IRC를 하면되나?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.322110Z","iopub.status.idle":"2025-10-11T13:58:24.322396Z","shell.execute_reply.started":"2025-10-11T13:58:24.322268Z","shell.execute_reply":"2025-10-11T13:58:24.322280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 모델 한번 돌려보기","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n\n# 간단한 CNN 모델 예시\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(32 * 128 * 128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n    def forward(self, x):\n        x = self.features(x)\n        print(x.shape)  # feature map shape 확인\n        x = x.view(x.size(0), -1)\n    \n        x = self.classifier(x)\n        return x\n\n# 데이터셋\nimages = RSNADataSet() # 이미지 데이터 (이미 준비된 텐서)\ndataloader = DataLoader(images, batch_size=8, shuffle=True)\nlabels = torch.tensor([1, 0], dtype=torch.float32) # 라벨\n\n# 모델 인스턴스\nmodel = SimpleCNN()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# 학습 예시\nmodel.train()\nfor epoch in range(10):\n    for batch in dataloader:\n        images, labels, _, _ = batch\n        labels = labels[:, 1].float()  # 양성 라벨만 선택\n\n        outputs = model(images)\n        loss = criterion(outputs.squeeze(), labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T13:58:24.324181Z","iopub.status.idle":"2025-10-11T13:58:24.324520Z","shell.execute_reply.started":"2025-10-11T13:58:24.324348Z","shell.execute_reply":"2025-10-11T13:58:24.324360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ","metadata":{}}]}